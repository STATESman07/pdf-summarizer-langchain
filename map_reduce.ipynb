{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b236069",
   "metadata": {},
   "source": [
    "## Map-reduce Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6b857ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11464885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000026164F76FB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000261639F8B50>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "llm=ChatGroq(api_key=api_key,model=\"llama-3.3-70b-versatile\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7130003b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'bias_variance.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='NBbS $sR <$\\x1bYS $sR\\nNBbSzs\\x84$st{\\x82<$\\x1bYSzs\\x84$st{\\x82\\n<$\\x1bYS $sR\\nNBbSzs\\x84$st{\\x82\\nNBbS $sR\\n<$\\x1bYSzs\\x84$st{\\x82\\n=tI\\x82\\x84TP$\\x1c\\x1c$t\\x1b !%\\x82\\x84TP$\\x1c\\x1c$t\\x1bFZR\\x1cSi$\\x1bY\\x1c\\n $sR\\nzs\\x84$st{\\x82\\ne\\x84\\x84B\\x84\\n_\\x84\\x82P\\x82\\x84\\x84\\x82IS$PSR$9\\x82S\\nBPSIs\\x1csR\\x82\\x1cS$RSR8sjj\\n_\\x84\\x82P\\x82\\x84\\x84\\x82IS$PSR$9\\x82S\\nBPSIs\\x1csR\\x82\\x1cS$RSjs\\x84\\x1b\\x82\\nWhat is Bias?‚Ä¢Error between average model prediction and ground truth‚Ä¢The bias of the estimated function tells us the capacity of the underlying model to predict the valuesWhat is Variance?‚Ä¢Average variability in the model prediction for the given dataset‚Ä¢The variance of the estimated function tells you how much the function can adjust to the change in the datasetHigh Bias\\nHigh Variance\\nOverly-simplified ModelUnder-fittingHigh error on both test and train dataOverly-complex ModelOver-fittingLow error on train data and high on testStarts modelling the noise in the input\\nBias variance Trade-off‚Ä¢Increasing bias (notalways)reduces variance and vice-versa‚Ä¢Error = bias2+ variance +irreducible error‚Ä¢The best model is where the error is reduced.‚Ä¢Compromise between bias and variance\\nCheat Sheet ‚ÄìBias-Variance Tradeoff\\nSource: https://www.cheatsheets.aqeel-anwar.com\\nMinimum Error\\nTutorial: Click here'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'bias_variance.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='Source: https://www.cheatsheets.aqeel-anwar.com\\nClassifier that always predicts label blue yields prediction accuracy of 90%\\nBlue: Label 1Green: Label 0Accuracy =Correct PredictionsTotal Predictions\\nCheat Sheet ‚ÄìImbalanced Data in Classification\\nAccuracy= TPTN+TPFN+FPTN++TPTPFN+Recall, Sensitivity=True +verate\\nTrue  PositiveFalse  Positive\\nFalse NegativeTrue Negative\\nActual Labels1 0\\nPredicted Labels0 1\\nTNTNFP+Specificity = \\nTPTPFP+Precision= FPTNFP+False +verate = \\nF1 score = 2x(Prec+ Rec) (Precx Rec) \\n(Is your prediction correct?) (What did you predict)True    Negative(Your prediction is correct)                           (You predicted 0)\\nPerformance metrics associated with Class 1\\nAccuracy:  %age correct prediction      Correct prediction over total predictionsOne value for entire networkPrecision: Exactnessof modelFrom the detected cats, how many were   Each class/label has a valueactually catsRecall:     Completenessof modelCorrectly detected cats over total catsEach class/label has a valueF1 Score: Combines Precision/RecallHarmonic mean of Precision and RecallEach class/label has a value\\nAccuracy doesn‚Äôt always give the correct insight about your trained model\\nPossible solutions1.Data Replication: Replicate the available data until the number of samples are comparable2.Synthetic Data: Images: Rotate, dilate, crop, add noise to existing input images and create new data3.Modified Loss: Modify the loss to reflect greater error when misclassifying smaller sample set\\nBlue: Label 1Green: Label 0\\nNo straight line (y=ax) passing through origin can perfectly separate data. Best solution: line y=0, predict all labels blueStraight line (y=ax+b) can perfectly separate data.Green class will no longer be predicted as blue\\nIncrease model complexity\\nùëôùëúùë†ùë†=ùëé‚àóùíçùíêùíîùíîùíàùíìùíÜùíÜùíè+ùëè‚àóùíçùíêùíîùíîùíÉùíçùíñùíÜùëé>ùëè\\nBlue: Label 1Green: Label 0\\n4.Change the algorithm: Increase the model/algorithm complexity so that the two classes are perfectly separable (Con: Overfitting)\\nSource: https://www.cheatsheets.aqeel-anwar.com\\nTutorial: Click here'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'bias_variance.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='Source: https://www.cheatsheets.aqeel-anwar.com\\nCheat Sheet ‚ÄìPCA Dimensionality Reduction\\nFeature # 1 (F1)Feature # 2 (F2)\\nVariance\\nF2F1 Feature # 2\\nFeature # 1New Feature # 1New Feature # 2\\nVariance\\nF2F1\\nVariance\\nF2F2Feature # 2\\nFeature # 1New Feature # 1New Feature # 2\\nWhat is PCA?‚Ä¢Based on the dataset find a new set of orthogonal feature vectors in such a way that the data spread is maximum in the direction of the feature vector (or dimension)‚Ä¢Rates the feature vector in the decreasing order of data spread (or variance)‚Ä¢The datapoints have maximum variance in the first feature vector, and minimum variance in the last feature vector‚Ä¢The variance of the datapoints in the direction of feature vector can be termed as a measure of information in that direction.Steps1.Standardize the datapoints2.Find the covariance matrix from the given datapoints3.Carry out eigen-value decomposition of the covariance matrix4.Sort the eigenvalues and eigenvectorsDimensionality Reduction with PCA‚Ä¢Keep the first m out of n feature vectors rated by PCA. These m vectors will be the best m vectors preserving the maximum information that could have been preserved with m vectors on the given datasetSteps:1.Carry out steps 1-4 from above2.Keep first m feature vectors from the sorted eigenvector matrix3.Transform the data for the new basis (feature vectors)4.The importance of the feature vector is proportional to the magnitude of the eigen value\\nFigure 1: Datapoints with feature vectors as x and y-axisFigure 2: The cartesian coordinate system is rotated to maximize the standard deviation along any one axis (new feature # 2)Figure 3: Remove the feature vector with minimum standard deviation of datapoints (new feature # 1) and project the data on new feature # 2\\nFigure 2Figure 1\\nFigure 3\\nSource: https://www.cheatsheets.aqeel-anwar.com'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'bias_variance.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='Source: https://www.cheatsheets.aqeel-anwar.com\\nSource: https://www.cheatsheets.aqeel-anwar.com\\nCheat Sheet ‚ÄìBayes Theorem and ClassifierWhat is Bayes‚ÄôTheorem?‚Ä¢Describestheprobabilityofanevent,basedonpriorknowledgeofconditionsthatmightberelatedtotheevent.\\nLikelihoodPrior Probability\\nEvidence\\nBayes‚ÄôTheorem\\nPosterior Probability\\nP(B A)\\nP(A B)\\nP(A)P(B)\\nExample‚Ä¢Probability of fire P(F) = 1%‚Ä¢Probability of smoke P(S) = 10%‚Ä¢Prob of smoke given there is a fire P(S F) = 90%‚Ä¢What is the probability that there is a fire given we see a smoke P(F S)?\\n‚Ä¢HowtheprobabilityofaneventchangeswhenwehaveknowledgeofanothereventP(A)P(AB)Usually, a better estimate than P(A)\\nMaximum AposterioriProbability (MAP) EstimationTheMAPestimateoftherandomvariabley,giventhatwehaveobservediid(x1,x2,x3,‚Ä¶),isgivenby.Wetrytoaccommodateourpriorknowledgewhenestimating.\\nMaximum Likelihood Estimation (MLE)TheMAPestimateoftherandomvariabley,giventhatwehaveobservediid(x1,x2,x3,‚Ä¶),isgivenby.Weassumewedon‚Äôthaveanypriorknowledgeofthequantitybeingestimated.\\nMLE is a special case of MAP where our prior is uniform (all values are equally likely)\\nNa√Øve Bayes‚ÄôClassifier (Instantiation of MAP as classifier)Suppose we have two classes, y=y1and y=y2. Say we have more than one evidence/features (x1, x2, x3, ‚Ä¶), using Bayes‚Äôtheorem\\nNa√Øve Bayes‚Äôtheorem assumes the features (x1, x2, ‚Ä¶) are i.i.d. i.e\\nMAP\\nMLE\\nÀÜ\\nÀÜ\\ny that maximizes the product of priorand likelihood\\ny that maximizes only the likelihood'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'bias_variance.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='Source: https://www.cheatsheets.aqeel-anwar.com\\nCheat Sheet ‚ÄìRegression AnalysisWhatisRegressionAnalysis?Fittingafunctionf(.)todatapointsyi=f(xi)undersomeerrorfunction.Basedontheestimatedfunctionanderror,wehavethefollowingtypesofregression\\nWhat does it fit?Estimated functionError FunctionLinear A line in n dimensionsPolynomialA polynomial of order kBayesian LinearGaussian distribution for each pointRidge Linear/polynomialLASSO Linear/polynomialLogisticLinear/polynomial with sigmoid\\ny\\nx\\nLinear Regression\\ny\\nx\\nPolynomial Regression\\ny\\nx\\nLogistic RegressionLabel 1\\nLabel 0\\ny\\nx\\nBayesian Linear Regression\\n1.LinearRegression:Fitsalineminimizingthesumofmean-squarederrorforeachdatapoint.2.PolynomialRegression:Fitsapolynomialoforderk(k+1unknowns)minimizingthesumofmean-squarederrorforeachdatapoint.3.BayesianRegression:Foreachdatapoint,fitsagaussiandistributionbyminimizingthemean-squarederror.Asthenumberofdatapointsxiincreases,itconvergestopointestimatesi.e.4.RidgeRegression:Canfiteitheraline,orpolynomialminimizingthesumofmean-squarederrorforeachdatapointandtheweightedL2normofthefunctionparametersbeta.5.LASSORegression:Canfiteitheraline,orpolynomialminimizingthethesumofmean-squarederrorforeachdatapointandtheweightedL1normofthefunctionparametersbeta.6.LogisticRegression:Canfiteitheraline,orpolynomialwithsigmoidactivationminimizingthebinarycross-entropylossforeachdatapoint.Thelabelsyarebinaryclasslabels.VisualRepresentation:\\nSummary:\\nTutorial: Click here'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'bias_variance.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='Source: https://www.cheatsheets.aqeel-anwar.com\\nCheat Sheet ‚ÄìRegularization in ML\\nTypesofRegularization:1.Modifythelossfunction:‚Ä¢L2Regularization:Preventstheweightsfromgettingtoolarge(definedbyL2norm).Largertheweights,morecomplexthemodelis,morechancesofoverfitting.\\n‚Ä¢L1Regularization:Preventstheweightsfromgettingtoolarge(definedbyL1norm).Largertheweights,morecomplexthemodelis,morechancesofoverfitting.L1regularizationintroducessparsityintheweights.Itforcesmoreweightstobezero,thanreducingthetheaveragemagnitudeofallweights\\n‚Ä¢Entropy:Usedforthemodelsthatoutputprobability.Forcestheprobabilitydistributiontowardsuniformdistribution.\\n2.Modifydatasampling:‚Ä¢Dataaugmentation:Createmoredatafromavailabledatabyrandomlycropping,dilating,rotating,addingsmallamountofnoiseetc.‚Ä¢K-foldCross-validation:Dividethedataintokgroups.Trainon(k-1)groupsandteston1group.Tryallkpossiblecombinations.3.Changetrainingapproach:‚Ä¢Injectingnoise:Addrandomnoisetotheweightswhentheyarebeinglearned.Itpushesthemodeltoberelativelyinsensitivetosmallvariationsintheweights,henceregularization‚Ä¢Dropout:Generallyusedforneuralnetworks.Connectionsbetweenconsecutivelayersarerandomlydroppedbasedonadropout-ratioandtheremainingnetworkistrainedinthecurrentiteration.Inthenextiteration,anothersetofrandomconnectionsaredropped.\\nWhat is Regularization in ML?‚Ä¢Regularizationisanapproachtoaddressover-fittinginML.‚Ä¢Overfittedmodelfailstogeneralizeestimationsontestdata‚Ä¢Whentheunderlyingmodeltobelearnedislowbias/highvariance,orwhenwehavesmallamountofdata,theestimatedmodelispronetoover-fitting.‚Ä¢Regularizationreducesthevarianceofthemodel\\n<$\\x1bYS $sRNBbSzs\\x84$st{\\x82 NBbS $sR<$\\x1bYSzs\\x84$st{\\x82\\n=tI\\x82\\x84TP$\\x1c\\x1c$t\\x1b !%\\x82\\x84TP$\\x1c\\x1c$t\\x1bFZR\\x1cSi$\\x1bY\\x1c\\n $sRzs\\x84$st{\\x82e\\x84\\x84B\\x84\\n_\\x84\\x82P\\x82\\x84\\x84\\x82IS$PSR$9\\x82SBPSIs\\x1csR\\x82\\x1cS$RSR8sjj _\\x84\\x82P\\x82\\x84\\x84\\x82IS$PSR$9\\x82SBPSIs\\x1csR\\x82\\x1cS$RSjs\\x84\\x1b\\x82\\n5-fold cross-validationTest TrainTestTestTestTest\\nTrainTrainTrainTrainTrainTrainTrain\\nConnections = 16Active = 11 (70%) \\nDropout-ratio = 30%\\nActive = 11 (70%)\\nOriginal Network\\nFigure 2. K-fold CV Figure 3. Drop-out\\nFigure 1. Overfitting\\nTutorial: Click here'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'bias_variance.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='Source: https://www.cheatsheets.aqeel-anwar.com\\nCheat Sheet ‚ÄìConvolutional Neural Network\\nConvolutionalNeuralNetwork:ThedatagetsintotheCNNthroughtheinputlayerandpassesthroughvarioushiddenlayersbeforegettingtotheoutputlayer.Theoutputofthenetworkiscomparedtotheactuallabelsintermsoflossorerror.Thepartialderivativesofthislossw.r.tthetrainableweightsarecalculated,andtheweightsareupdatedthroughoneofthevariousmethodsusingbackpropagation.CNNTemplate:Mostofthecommonlyusedhiddenlayers(notall)followapattern1.Layerfunction:Basictransformingfunctionsuchasconvolutionalorfullyconnectedlayer.a.FullyConnected:Linearfunctionsbetweentheinputandtheoutput.\\n-2.0-1.00.01.02.00.00.51.01.52.02.53.03.54.0 MSE Lossmse = (x¬∞ÀÜx)2mse = (x¬∞ÀÜx)2\\n-2.0-1.00.01.02.00.00.250.50.751.01.251.51.752.0 MAE Lossmae =‚ô£x¬∞ÀÜx‚ô£mae =‚ô£x¬∞ÀÜx‚ô£\\n-2.0-1.00.01.02.00.00.250.50.751.01.251.51.752.0 Huber LossŒ©12(x¬∞ÀÜx)2 :‚ô£x¬∞ÀÜx‚ô£<‚àû‚àû‚ô£x¬∞ÀÜx‚ô£¬∞12‚àû2 :else√¶\\n‚àû=1.9\\nŒ©12(x¬∞ÀÜx)2 :‚ô£x¬∞ÀÜx‚ô£<‚àû‚àû‚ô£x¬∞ÀÜx‚ô£¬∞12‚àû2 :else√¶\\n‚àû=1.9\\n-2.0-1.00.01.02.00.00.51.01.52.02.53.0 Hinge LossŒ©max(0‚Ü™1¬∞ÀÜx):x=1max(0‚Ü™1+ÀÜx):x=¬∞1√¶Œ©max(0‚Ü™1¬∞ÀÜx):x=1max(0‚Ü™1+ÀÜx):x=¬∞1√¶\\n0‚äø0 0‚äø2 0‚äø4 0‚äø6 0‚äø8 1‚äø00.02.04.06.08.0Cross Entropy Loss¬∞ylog(p)¬∞(1¬∞y)log(1¬∞p)¬∞ylog(p)¬∞(1¬∞y)log(1¬∞p)\\n0‚äø0 0‚äø2 0‚äø4 0‚äø6 0‚äø8 1‚äø00‚äø0\\n0‚äø2\\n0‚äø4\\n0‚äø6\\n0‚äø8\\n1‚äø0\\nInput MapKernelOutput Map\\nConvolutional Layer\\na.ConvolutionalLayers:Theselayersareappliedto2D(3D)inputfeaturemaps.Thetrainableweightsarea2D(3D)kernel/filterthatmovesacrosstheinputfeaturemap,generatingdotproductswiththeoverlappingregionoftheinputfeaturemap.b.TransposedConvolutional(DeConvolutional)Layer:Usuallyusedtoincreasethesizeoftheoutputfeaturemap(Upsampling)Theideabehindthetransposedconvolutionallayeristoundo(notexactly)theconvolutionallayer\\n2.Pooling:Non-trainablelayertochangethesizeofthefeaturemapa.Max/AveragePooling:Decreasethespatialsizeoftheinputlayerbasedonselectingthemaximum/averagevalueinreceptivefielddefinedbythekernelb.UnPooling:Anon-trainablelayerusedtoincreasethespatialsizeoftheinputlayerbasedonplacingtheinputpixelatacertainindexinthereceptivefieldoftheoutputdefinedbythekernel.\\n3.Normalization:Usuallyusedjustbeforetheactivationfunctionstolimittheunboundedactivationfromincreasingtheoutputlayervaluestoohigha.LocalResponseNormalizationLRN:Anon-trainablelayerthatsquare-normalizesthepixelvaluesinafeaturemapwithinalocalneighborhood.b.BatchNormalization:Atrainableapproachtonormalizingthedatabylearningscaleandshiftvariableduringtraining.3.Activation:Introducenon-linearitysoCNNcanefficientlymapnon-linearcomplexmapping.a.Non-parametric/Staticfunctions:Linear,ReLUb.Parametricfunctions:ELU,tanh,sigmoid,LeakyReLUc.Boundedfunctions:tanh,sigmoid\\n5.Lossfunction:QuantifieshowfarofftheCNNpredictionisfromtheactuallabels.a.RegressionLossFunctions:MAE,MSE,Huberlossb.ClassificationLossFunctions:Crossentropy,Hingeloss\\nw11*x1 + b1\\nInput Node Output Node \\nw21*x2 + b1\\nw31*x3 + b1\\nx1x2x3\\ny1Fully Connected Layer\\nTutorial: Click here'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'bias_variance.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='Source: https://www.cheatsheets.aqeel-anwar.com\\nCheat Sheet ‚ÄìFamous CNNs\\nAlexNet‚Äì2012Why:AlexNetwasbornoutoftheneedtoimprovetheresultsoftheImageNetchallenge.What:Thenetworkconsistsof5Convolutional(CONV)layersand3FullyConnected(FC)layers.TheactivationusedistheRectifiedLinearUnit(ReLU).How:Dataaugmentationiscarriedouttoreduceover-fitting,UsesLocalresponselocalization.VGGNet‚Äì2014Why:VGGNetwasbornoutoftheneedtoreducethe#ofparametersintheCONVlayersandimproveontrainingtimeWhat:TherearemultiplevariantsofVGGNet(VGG16,VGG19,etc.)How:Theimportantpointtonotehereisthatalltheconvkernelsareofsize3x3andmaxpoolkernelsareofsize2x2withastrideoftwo.ResNet‚Äì2015Why:NeuralNetworksarenotoriousfornotbeingabletofindasimplermappingwhenitexists.ResNetsolvesthat.What:TherearemultipleversionsofResNetXXarchitectureswhere‚ÄòXX‚Äôdenotesthenumberoflayers.ThemostusedonesareResNet50andResNet101.Sincethevanishinggradientproblemwastakencareof(moreaboutitintheHowpart),CNNstartedtogetdeeperanddeeperHow:ResNetarchitecturemakesuseofshortcutconnectionsdosolvethevanishinggradientproblem.ThebasicbuildingblockofResNetisaResidualblockthatisrepeatedthroughoutthenetwork.\\nInception‚Äì2014Why:Lagerkernelsarepreferredformoreglobalfeatures,ontheotherhand,smallerkernelsprovidegoodresultsindetectingarea-specificfeatures.Foreffectiverecognitionofsuchavariable-sizedfeature,weneedkernelsofdifferentsizes.ThatiswhatInceptiondoes.What: The Inception network architecture consists of several inception modules of the following structure. Each inception module consists of four operations in parallel, 1x1 conv layer, 3x3 conv layer, 5x5 conv layer, max poolingHow: Inception increases the network space from which the best network is to be chosen via training. Each inception module can capture salient features at different levels.\\nFilter Concatenation\\nPrevious Layer\\n5x5 Conv3x3 Conv 1x1 Conv1x1 Conv1x1 Conv3x3 Maxpool1x1 Conv\\nFigure 2 Inception Block\\nWeight layerWeight layer+\\nf(x) x\\nf(x)+xFigure 1 ResNetBlock\\nTutorial: Click here'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'bias_variance.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='Source: https://www.cheatsheets.aqeel-anwar.com\\nCheat Sheet ‚ÄìEnsemble Learning in ML\\nComplete datasetTrain Weak Model #1Train Weak Model #2Train Weak Model #3Train Weak Model #4\\nInput DatasetStep #1Assign equal weights to all the datapoints in the dataset\\nStep #(n+1)aTrain a weak model with adjusted weights on all the datapoints in the dataset\\nEnsemble Method ‚ÄìBoostingUniform weightsAdjusted weightsalpha1Adjusted weightsalpha2Adjusted weightsalpha3\\nxxxxalpha3\\nVotingFinal PredictionStep #n+2In the test phase, predict from each weak model and vote their predictions weighted by the corresponding alpha to get final prediction\\nStep #2aTrain a weak model with equal weights to all the datapointsStep #2b‚Ä¢Based on the final error on the trained weak model, calculate a scalar alpha. ‚Ä¢Use alpha to increase the weights of wrongly classified points, and decrease the weights of correctly classified points Step #3aTrain a weak model with adjusted weights on all the datapoints in the datasetStep #3b‚Ä¢Based on the final error on the trained weak model, calculate a scalar alpha. ‚Ä¢Use alpha to increase the weights of wrongly classified points, and decrease the weights of correctly classified points \\nInput Dataset\\nSubset #1 ‚ÄìWeak LearnersSubset #3Subset #2 ‚ÄìMeta LearnerTrain Weak Model #1Train Weak Model #2Train Weak Model #3Train Weak Model #4Input DatasetStep #1Create 2 subsets from original dataset, one for training weak models and one for meta-modelStep #2Train each weak model with the weak learner dataset\\nStep #3Train a meta-learner for which the input is the outputs of the weak models for the Meta Learner datasetTrained Weak Model #1Trained Weak Model #2Trained Weak Model #3Trained Weak Model #4Subset #1 ‚ÄìWeak LearnersSubset #2 ‚ÄìMeta Learner\\nMeta ModelFinal PredictionStep #4In the test phase, feed the input to the weak models, collect the output and feed it to the meta model. The output of the meta model is the final prediction\\nEnsemble Method ‚ÄìStacking\\nStep #2Train each weak model with an independent subset, in parallel\\nSubset #1Subset #2Subset #3Subset #4Weak Model #1Weak Model #2Weak Model #3Weak Model #4VotingFinal Prediction\\nInput DatasetStep #1Create N subsets from original dataset, one for each weak model\\nStep #3In the test phase, predict from each weak model and vote their predictions to get final prediction\\nEnsemble Method ‚ÄìBagging\\nParameterBaggingBoostingStackingFocuses onReducing varianceReducing biasImproving accuracyNature of weak learners isHomogenousHomogenousHeterogenousWeak learners are aggregated bySimple votingWeighted votingLearned voting (meta-learner)\\nWhatisEnsembleLearning?WisdomofthecrowdCombinemultipleweakmodels/learnersintoonepredictivemodeltoreducebias,varianceand/orimproveaccuracy.TypesofEnsembleLearning:Nnumberofweaklearners1.Bagging:TrainsNdifferentweakmodels(usuallyofsametypes‚Äìhomogenous)withNnon-overlappingsubsetoftheinputdatasetinparallel.Inthetestphase,eachmodelisevaluated.Thelabelwiththegreatestnumberofpredictionsisselectedastheprediction.Baggingmethodsreducesvarianceoftheprediction2.Boosting:TrainsNdifferentweakmodels(usuallyofsametypes‚Äìhomogenous)withthecompletedatasetinasequentialorder.Thedatapointswronglyclassifiedwithpreviousweakmodelisprovidedmoreweightstothattheycanbeclassifiedbythenextweakleanerproperly.Inthetestphase,eachmodelisevaluatedandbasedonthetesterrorofeachweakmodel,thepredictionisweightedforvoting.Boostingmethodsdecreasesthebiasoftheprediction.3.Stacking:TrainsNdifferentweakmodels(usuallyofdifferenttypes‚Äìheterogenous)withoneofthetwosubsetsofthedatasetinparallel.Oncetheweaklearnersaretrained,theyareusedtotrainedametalearnertocombinetheirpredictionsandcarryoutfinalpredictionusingtheothersubset.Intestphase,eachmodelpredictsitslabel,thesesetoflabelsarefedtothemetalearnerwhichgeneratesthefinalprediction.Theblockdiagrams,andcomparisontableforeachofthesethreemethodscanbeseenbelow.\\nTutorial: Click here'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'bias_variance.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='Source: https://www.cheatsheets.aqeel-anwar.com\\n5. HashTable\\n2. Linked List‚Ä¢LinkedListdoesnothavetheirorderdefinedbytheirphysicalplacementinthememory.‚Ä¢Contiguouselementsofthelinkedlistarenotplacedadjacenttoeachotherinthememory.\\n1.List‚Ä¢ Orderedcollection of elements‚Ä¢ The position of each element is defined by the index‚Ä¢ The elements can be accessed in any order\\nCheat Sheet ‚ÄìData Structures\\n12 2 0head None\\n12\\n0 2 6\\n18\\nx Node/Vertex\\nEdge\\naddressvalue0x00val00x02val10x04val2‚Ä¶ ‚Ä¶\\nHash Functionfhash\\nkey0val0\\nkey1val1\\nkey2val2\\n12\\n2 6\\n18\\n60\\n36 8\\nroot\\nsub-tree\\nparent\\nchildren\\ndepth=3\\n20\\nendfront\\n20 12\\nend front12\\nDequeue()\\n18\\nEnqueue()\\n18\\n20\\nendfront20\\nend front\\nbefore\\nafter\\nbefore\\nafter\\n122 0 6value 18\\n0 1 2 3index 4\\nlen= 4\\n4. Queue12206\\npush()6\\n1220\\nbeforeafter 12206\\npop()6\\n1220\\nbeforeafter 12206\\ntop()6\\n12206\\nbeforeafter\\n3. Stack\\n4. Tree\\n4. Graph‚Ä¢A graph is a pair of sets(V, E), whereVis set of all the vertices, Eis set of all edges. ‚Ä¢A neighbor of a node is set of all vertices connected with that node through an edge. ‚Ä¢As opposed to trees, a graph can be cyclic, which means starting from a node and following the edges, you can end up on the same node\\n‚Ä¢Each linked list element contains both the values and the address (pointer) to the next linked list element. ‚Ä¢Hence the linked list can only be traversed sequentially going through each element at a time\\n‚Ä¢Stack is a sequential data structurewhich maintains the order of elements as they were inserted in.‚Ä¢Last In First Out (LIFO) order, which means that the elements can only be accessed in thereverse orderas they were inserted into the stack. ‚Ä¢The element to beinserted last,will thefirst one to get removed from the stack.‚Ä¢Push()adds an element at the headof the stack, whilepop()removes an element from the headof the stack‚Ä¢A real-life example of a stack is a stack of kitchen plates\\n‚Ä¢A queue is a sequential data structure that maintains the order of elements as they were inserted in‚Ä¢First In First Out (FIFO), the element to beinserted first, will thefirst one to get removedfrom the queue‚Ä¢Whenever an element is added (Enqueue()) it is added to the endof the queue. On the other hand, element removal (Dequeue()) is done from the frontof the queue.‚Ä¢A real-life example is a check-out line at a grocery store‚Ä¢Creates paired assignments (key mapped to values) sothe pairs can be accessed in constant time‚Ä¢For each(key, value)pair, the key is passed through a hash function to create a unique physical address for the value to be stored in the memory.‚Ä¢Hash function can end up generating the same physical address for different keys. This is called acollision.‚Ä¢Maintains a hierarchical relation between its elements.‚Ä¢RootNode‚àíThe node at the top of the tree‚Ä¢Parent Node‚àíAny node that has at least one child ‚Ä¢Child Node‚àíThe successor of a parent node is known as a child node. A node can be both a parent and a child node. The root is never a child node.‚Ä¢Leaf Node‚àíThe node which does not have any child node. ‚Ä¢Traversing‚àíPassing through the nodes in a certain order, e.gBFS, DFS\\nTutorial: Clickhere'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'bias_variance.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='Source: https://www.cheatsheets.aqeel-anwar.com\\nPart 1 ‚ÄìHow to prepare for coding interviews?*‚Ä¢The timeline: \\n‚Ä¢Review Data structures and Complexities:The following 7 data structures are necessary for the interview, and their time/space complexity‚Ä¢List/Arrays, Linked List, Hash Table/dictionary, Tree, Graph, Heap, Queue ‚Ä¢Click herefor tutorial.‚Ä¢Practice coding questions:‚Ä¢Multiple online resources such as LeetCode.com, InterviewBit.com, HackerRank.com etc.‚Ä¢Pick one online resource and aim for easy and medium coding questions (approx. 100-150).‚Ä¢Beginners start preparing 2-3 months before the interview, and intermediates about 1 month.‚Ä¢Note:‚Ä¢From my personal experience, paid subscription of LeetCode.com was worth it.‚Ä¢Facebook, Uber, Google and Microsoft tagged question of LeetCode covered almost 90% of the questions asked\\nCheat Sheet ‚ÄìPreparing for Coding Interviews\\nPart 2 ‚ÄìHow to answer a coding question?*‚Ä¢Listen to the questionThe interviewer will explain the question with an example. Note down the important points.‚Ä¢Talk about your understanding of the questionRepeat the question and confirm your understanding. Ask clarifying questions such as1.Input/Output data type limitations2.Input size/length limitations3.Special/Corner cases‚Ä¢Discuss your approachWalk through how would you approach the problem and ask the interviewer if he agrees with it.Talk about the data structure you prefer and why. Discuss the solution with the bigger picture.‚Ä¢Start codingAsk the interviewer if you could start coding. Define useful functions and explain as you write. Think out loud so the interviewer can evaluate your thought process.‚Ä¢Discuss the time and space complexityDiscuss the time and space complexity in terms of Big O for your coded approach. ‚Ä¢Optimize the approachIf your approach is not the most optimized one, the interviewer will hint you a few improvements. Pay attention to hints and try to optimize your code.\\nFig. 2 ‚ÄìHow to answer a coding question?\\nListen & Repeat\\nAsk Clarifying Questions\\nWalk through your approach\\nStart Coding\\nDiscuss Time & Space complexity\\nOptimize\\nGraduationStart preparingStart applying for jobs\\n1 month3 monthsFig. 1 ‚ÄìPreparation Timeline for Coding Interviews\\n*Disclaimer: The recommendations are based on personal experiences of the author. The mentioned approach and resources might work great for some, but not so much for others.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'bias_variance.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='How to prepare for behavioral interview?Collect stories, assign keywords, practicethe STAR format\\n1/4KeywordsList important keywords that will be populated with your personal stories. Most common keywords are given in the table belowConflict ResolutionNegotiationCompromise to achieve goalCreativityFlexibilityConvincingHandling CrisisChallenging SituationWorking with difficult peopleAnother team priorities not alignedAdjust to a colleague styleTake StandHandling ‚ÄìvefeedbackCoworker view of youWorking with a deadlineYour strengthYour weaknessInfluence OthersHandling failureHandling unexpected situationConverting challenge to opportunityDecision without enough dataConflict ResolutionMentorship/Leadership\\nStories1.List all the organizations you have been a part of. For example1.Academia: BSc, MSc, PhD2.Industry: Jobs, Internship3.Societies: Cultural, Technical, Sports2.Think of stories from step 1 that can fall into one of the keywords categories. The more stories the better. You should have at least 10-15 stories.3.Create a summary table by assigning multiple keywords to each stories. This will help you filter out the stories when the question asked in the interview. An example can be seen belowStory1: [Convincing][TakeStand][influenceother]Story2: [Mentorship][Leadership]Story3: [Conflictresolution][Negotiation]Story4: [decision-without-enough-data]\\nSTAR FormatWrite down the stories in the STAR format as explained in the 2/4 part of this cheat sheet. This will help you practice the organization of story in a meaningful way.\\nSource: https://www.cheatsheets.aqeel-anwar.com\\nIcon Source: www.flaticon.comTutorial: Click here'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'bias_variance.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='How to prepare for behavioral interview?Direct*, meaningful*,personalized*, logical**(Respective colors are used to identify these characteristics in the example)\\nExample: ‚ÄúTell us about a time when you had to convince senior executives‚Äù\\nIcon Source: www.flaticon.com\\nSTAR\\nSituationExplain the situation and provide necessary context for your story.\\nTaskExplain the task and your responsibility in the situation\\nActionWalk through the steps and actions you took to address the issue\\nResultState the outcome of the result of your actions\\n‚ÄúIworkedasaninterninXYZcompanyinthesummerof2019.Theprojectdetailsprovidedtomewaselaborative.Aftersomeinitialbrainstorming,andresearchIrealizedthattheprojectapproachcanbemodifiedtomakeitmoreefficientintermsoftheunderlyingKPIs.Idecidedtotalktomymanageraboutit.‚Äù\\n‚ÄúIhadanhour-longcallwithmymanagerandexplainedhimindetailtheproposedapproachandhowitcouldimprovetheKPIs.Iwasabletoconvincehim.HeaskedmeifIwillbeabletopresentmyproposedapproachforapprovalinfrontofthehigherexecutives.Iagreedtoit.IwasworkingoutoftheABC(city)officeandtheexecutivesneedtoflyinfromXYZ(city)office.‚Äù\\n‚ÄúIdidaquickbackgroundcheckontheexecutivestoknowbetterabouttheirareaofexpertisesothatIcanconvincethemaccordingly.Ipreparedanelaborative15slidepresentationstartingwithexplainingtheirapproach,movingontomyproposedapproachandfinallycomparingthemonpreliminaryresults.\\n‚ÄúAftersomeactivediscussionwewereabletoestablishthattheproposedapproachwasbetterthantheinitialone.Theexecutivesproposedafewsmallchangestomyapproachandreallyappreciatedmystand.Attheendofmyinternship,Iwasselectedamongthe3outof68internswhogottomeettheseniorvicepresidentofthecompanyoverlunch.‚Äù\\n2/4\\nSource: https://www.cheatsheets.aqeel-anwar.com\\nIcon Source: www.flaticon.comTutorial: Click here'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'bias_variance.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='How to answer a behavioral question?Understand, Extract, Map, Select and ApplyExample: ‚ÄúTell us about a time when you had to convince senior executives‚Äù\\nIcon Source: www.flaticon.com\\nUnderstand\\nExtract\\nMap\\nSelect\\nApply\\nUnderstand the questionExample: A story where I was able to convince my seniors. Maybe they had something in mind, and I had a better approach and tried to convince them\\nExtract keywords and tagsExtract useful keywords that encapsulates the gist of the questionExample:[Convincing], [Creative], [Leadership]\\nMap the keyword to your storiesShortlist all the stories that fall under the keywords extracted from previous stepExample:Story1, Story2, Story3, Story4, ‚Ä¶, Story N\\nSelect the best story From the shortlisted stories, pick the one that best describes the question and has not been used so far in the interviewExample: Story3\\nApply the STAR methodApply the STAR method on the selected story to answer the questionExample: See Cheat Sheet 2/3 for details\\n3/4\\nSource: https://www.cheatsheets.aqeel-anwar.com\\nIcon Source: www.flaticon.comTutorial: Click here'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'bias_variance.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='Behavioral InterviewCheat SheetSummarizing the behavioral interview\\nHow to answer a question during interview\\nUUnderstand the questionUnderstand the question and clarify any confusions that you have\\nEMSA\\nExtract the keywordsTry to extract one or more of the keywords from the question\\nSelect a storySince each keyword maybe assigned to multiple stories, select the one that is most relevant and has not been used.\\nMap the keywords to storiesBased on the keywords extracted, find the stories using the summary table created during preparation (Step 4)\\nApply the START formatOnce the story has been shortlisted, apply STAR format on the story to answer the question.\\n1Gather important topics as keywordsUnderstand and collect all the important topics commonly asked in the interview\\n2345\\nHow to prepare for the interview\\nCollect your storiesBased on all the organizations you have been a part of, think of all the stories that fall under the keywords above\\nAssign keywords to storiesAssign each of your story one or more keywords. This will help you recall them quickly\\nPractice stories in STAR formatPractice each story using the STAR format. You will have to answer the question following this format.\\nCreate a summary tableCreate a summary table mapping stories to their associated keywords. This will be used during the behavioral question\\n4/4\\nSource: https://www.cheatsheets.aqeel-anwar.com\\nIcon Source: www.flaticon.comTutorial: Click here')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader=PyPDFLoader(\"bias_variance.pdf\")\n",
    "doc=loader.load_and_split()\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1995701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "split_text=RecursiveCharacterTextSplitter(chunk_size=2000,chunk_overlap=500).split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "970fb1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "chunk_prompt=\"\"\"You are an expert summarizer.\n",
    "\n",
    "Summarize the following text in 3-4 sentences:\n",
    "\n",
    "{text}\"\"\"\n",
    "\n",
    "chunk_prompt_template=PromptTemplate(\n",
    "    input_variable=[\"text\"],template=chunk_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9909b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt=\"\"\"\n",
    "You are a document analyst.\n",
    "\n",
    "Below are summaries of several sections of a larger document.\n",
    "Combine them into a single, concise summary:\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "final_prompt_template=PromptTemplate(\n",
    "    input_variable=[\"text\"],template=final_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e713f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "summary_chain=load_summarize_chain(llm=llm,chain_type=\"map_reduce\",\n",
    "                                map_prompt=chunk_prompt_template,\n",
    "                                combine_prompt=final_prompt_template,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e770ab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HARSHIT\\AppData\\Local\\Temp\\ipykernel_6628\\3252524847.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  summary_chain.run(split_text)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3032 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Here is a concise summary of the provided text in 3-4 paragraphs:\\n\\nThe concept of bias and variance is crucial in modeling, as it affects a model's predictive capacity. Techniques such as data replication, synthetic data generation, and loss function modification can address imbalanced data, while dimensionality reduction methods like Principal Component Analysis (PCA) help preserve important information. Additionally, machine learning techniques like regression analysis, Convolutional Neural Networks (CNNs), and ensemble learning are essential for modeling complex relationships between inputs and outputs.\\n\\nMachine learning techniques, including regression analysis and CNNs, can be combined using ensemble learning methods like Bagging, Boosting, and Stacking to reduce bias, variance, and improve accuracy. Understanding data structures, such as lists, linked lists, stacks, queues, trees, and hash tables, is also fundamental to programming and coding interviews. Practicing coding questions on platforms like LeetCode, InterviewBit, or HackerRank can help individuals prepare for coding interviews and demonstrate problem-solving skills.\\n\\nTo prepare for interviews, individuals should focus on both coding and behavioral aspects. For coding interviews, a step-by-step approach to answering questions can demonstrate problem-solving skills and thought process. For behavioral interviews, collecting personal stories that demonstrate skills and experiences, and practicing the STAR or START method to organize these stories, can help individuals make a positive impression on the interviewer. The UEMSA method can also be used to answer behavioral questions by understanding the question, extracting keywords, and mapping them to personal stories.\\n\\nBy preparing for both coding and behavioral interviews, individuals can increase their chances of success. This preparation involves understanding key concepts like bias and variance, practicing coding questions, and collecting personal stories to demonstrate skills and experiences. Effective use of methods like STAR, START, and UEMSA can also enable individuals to respond confidently and effectively to interview questions, ultimately making a positive impression on the interviewer and achieving success in their interviews.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_chain.run(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95d16ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose=False llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='You are an expert summarizer.\\n\\nSummarize the following text in 3-4 sentences:\\n\\n{text}'), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000026164F76FB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000261639F8B50>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}) reduce_documents_chain=ReduceDocumentsChain(verbose=False, combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='\\nYou are a document analyst.\\n\\nBelow are summaries of several sections of a larger document.\\nCombine them into a single, concise summary:\\n\\n{text}\\n'), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000026164F76FB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000261639F8B50>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='text')) document_variable_name='text'\n"
     ]
    }
   ],
   "source": [
    "print(summary_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917457f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
